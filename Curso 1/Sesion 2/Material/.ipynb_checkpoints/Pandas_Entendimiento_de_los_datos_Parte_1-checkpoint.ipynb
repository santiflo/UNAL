{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22zXjFMRkUkJ"
      },
      "source": [
        "<img src = \"https://drive.google.com/uc?export=view&id=1WaM3ez8iLaUk3VyWNYZQuifnvbEX4vbK\" alt = \"Encabezado MLDS\" width = \"100%\">  </img>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyyYqzShjxwL"
      },
      "source": [
        "# **Entendimiento de los datos con *pandas* I**\n",
        "---\n",
        "<img src = \"https://pandas.pydata.org/static/img/pandas.svg\" alt = \"pandas Logo\" width = \"70%\">  </img>\n",
        "\n",
        "\n",
        "\n",
        "***Pandas*** es una librería de código abierto de *Python* muy popular diseñada para tareas de análisis y manipulación de datos. Es, junto a *NumPy* y *SciPy*, un módulo fundamental del ecosistema de computación científica en *Python* que es usado en proyectos de análisis de datos.\n",
        "\n",
        "En este material se discutirán las funcionalidades que *pandas* ofrece para el proceso de entendimiento de los datos, desde sus estructuras de datos fundamentales, sus atributos y métodos principales, además de herramientas de escritura y lectura de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRKerH0JtAoP"
      },
      "source": [
        "## **1. Importar *pandas***\n",
        "---\n",
        "\n",
        "*pandas*, al igual que *NumPy*, viene instalado por defecto en la mayoría de distribuciones de *Python*. En este material, y en muchos recursos que encontrará en la web, se utilizará el alias **`pd`** como abreviatura de *pandas*. Si lo desea, puede trabajar sin alias o con módulos específicos, tal como se discutió en la guía de *NumPy*.\n",
        "\n",
        "*pandas* está construido encima de *NumPy* y depende de este para muchas de sus funcionalidades principales. Se recomienda instalar en conjunto estas librerías, pues juntas proveen una herramienta poderosa para la manipulación de conjuntos de datos. Se usará el alias **`np`** como abreviatura de *NumPy* y **`pd`** como abreviatura de *Pandas*.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If9LYvdhSImI"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fyqcKuKQfcN"
      },
      "source": [
        "!python --version\n",
        "print('NumPy', np.__version__)\n",
        "print('pandas', pd.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XBOPST5sDhp"
      },
      "source": [
        "Este material fue realizado con las siguientes versiones:\n",
        "\n",
        "- Python 3.10.6\n",
        "- NumPy 1.22.4\n",
        "- pandas 1.5.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W6-WrbATfqg"
      },
      "source": [
        "## **2. pd.Series y pd.DataFrame**\n",
        "---\n",
        "\n",
        "*Pandas* está orientado al manejo de datos de carácter tabular, como las tablas de hojas de cálculo o de bases de datos relacionales. Su funcionalidad gira en torno a dos estructuras de datos fundamentales:\n",
        "* **`Series`**\n",
        "* **`Dataframes`**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0UWE3c9Tr1D"
      },
      "source": [
        "### **2.1. *Series***\n",
        "---\n",
        "\n",
        "El primer objeto a considerar es el objeto *Series*. Una serie es un arreglo unidimensional de datos, cuyos elementos son identificados por un índice (no necesariamente uno único como en los diccionarios de *Python*). Se puede considerar como dos arreglos de *NumPy* asociados. Uno, el *índice* o **index** de la serie, cuyos valores corresponden a los valores usados para identificar cada entrada de la serie. El otro es el contenido de la serie, del mismo tamaño de su índice. Esta relación permite obtener los elementos en una serie de la forma en que se haría con un diccionario, permitiendo a su vez un espectro mayor de funcionalidad y utilidad para el análisis de datos.\n",
        "\n",
        "La forma principal de crear *Series* en *pandas* es mediante el constructor **`pd.Series`**. Esta función admite como argumento distintos tipos de dato y argumentos adicionales para la definición de series. Los tipos de dato permitidos son:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnfjeFL6D6OE"
      },
      "source": [
        "**1.  Listas o tuplas de Python**: Al usar listas de *Python* como entrada, su contenido se convierte en el contenido del nuevo objeto *Series*. El argumento **`index`** permite definir el índice de la lista. Si no se pasa este argumento el índice son los números enteros desde 0 hasta el tamaño de la serie, como en un arreglo o una lista."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RT78HCnDiVf"
      },
      "source": [
        "#Listas y tuplas de Python (Variables, listas/tuplas literales, comprensión de listas...)\n",
        "pd.Series(['a', 'b', 'c'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "347X-qLzTSpV"
      },
      "source": [
        "pd.Series(('a', 'b', 'c'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0wSEM4_EhiH"
      },
      "source": [
        "values = [f'Value: {i}' for i in range(10)]\n",
        "index  = [f'Index: {i}' for i in range(10)] # Índices con cadenas de caracteres\n",
        "\n",
        "serie = pd.Series(values,          # Valores de la serie\n",
        "                  index = index )  # Índice de la serie\n",
        "\n",
        "print(type(serie)) # Imprime el tipo de dato: Series\n",
        "serie"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Okdk1ZDGlHO"
      },
      "source": [
        "**2.  Arreglos de *NumPy***: Tanto el argumento de contenido como el argumento de índice **`index`** aceptan arreglos de *NumPy* en su definición. Como *pandas* y sus objetos están diseñados utilizando arreglos de *NumPy*, también se consideran los tipos de dato de *NumPy* para sus objetos. Estos pueden inferirse si provienen de una lista o un arreglo, o pueden especificarse con el argumento **`dtype`**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRP__PZHC_hn"
      },
      "source": [
        "#Arreglos de NumPy (Tanto para los valores como para el índice)\n",
        "pd.Series(np.logspace(0, 4, 10), index = np.linspace(0, 90, 10, dtype = 'int'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--iLtnaTHrAu"
      },
      "source": [
        "pd.Series(np.linspace(0, 500, 10), dtype = 'float16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJIu584lHE3A"
      },
      "source": [
        "**3.  Diccionarios de *Python***: El constructor también admite diccionarios de *Python* como argumento para su definición. Al recibir este tipo de dato, las llaves del diccionario se interpretan como el índice y sus valores asociados como el contenido de la serie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwcSu-V2Fgju"
      },
      "source": [
        "#Diccionarios\n",
        "data = {\n",
        "    'a' : 1,\n",
        "    'b' : 2,\n",
        "    'c' : 3\n",
        "    }\n",
        "pd.Series(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_PVO6E0NjlR"
      },
      "source": [
        "Además, se le puede añadir un nombre con el argumento **`name`**. Esto será de utilidad cuando se use de la mano con objetos **`pd.DataFrame`**, que se presentarán a continuación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAICLvYHTr92"
      },
      "source": [
        "### **2.2. DataFrame**\n",
        "---\n",
        "\n",
        "Los objetos **`pd.DataFrame`** son el objeto principal de *pandas*. Representan una tabla, un tipo de conjunto de datos con un índice asignado a sus filas y uno asignado a sus columnas. Cada fila o columna representa un objeto **`pd.Series`**.\n",
        "\n",
        "En el análisis de datos, se tiene una convención para distinguir entre filas y columnas. Las filas se suelen considerar observaciones, repeticiones de un experimento, o individuos de algo en particular. Por su parte, las columnas representan variables asociadas a cada observación (características), por lo que pueden tener distintos tipos de dato o semántica independiente. La intersección entre una fila y una columna se conoce como celda, y representa el valor de una variable de una instancia específica.\n",
        "\n",
        "Para crear un objeto *DataFrame* se puede utilizar el constructor **`pd.DataFrame`**. Al igual que las *Series*, este constructor admite distintos tipos de dato:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWMOxtqXQJOB"
      },
      "source": [
        "**1.  Arreglo de *NumPy*:**  Los datos de entrada se pueden especificar como un arreglo de *NumPy* de dos dimensiones. Al hacer esto, los valores de la primera dimensión (axis = 0) son organizados por filas, y los arreglos de la segunda dimensión (axis = 1) son organizados por columnas. Añadir un arreglo de 1 dimensión construye un *DataFrame* de 1 sola columna en lugar de una serie. Arreglos con otras dimensiones generarán un error.\n",
        "\n",
        "Esta vez, para distinguir entre filas y columnas se definen dos argumentos para la definición de los arreglos usados para representar sus índices. Estos son:\n",
        "\n",
        "*  **`index`**: Este argumento (igual al recibido por el constructor **`pd.Series`**) define el valor de los índices de las filas de la tabla.\n",
        "*  **`columns`**: Este argumento define el valor de los índices de las columnas de la tabla.\n",
        "\n",
        "No es necesario que estos argumentos contengan valores únicos, aunque es recomendable si se desea manejar cada elemento de forma aislada. También es válido usar combinaciones de tuplas y listas para esta definición."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH2ioTpLQfOv"
      },
      "source": [
        "#Arreglo de NumPy\n",
        "pd.DataFrame(np.full((3,7), 10), index = list('aba'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGSAUJ5_S4P0"
      },
      "source": [
        "#Combinación de tuplas y listas\n",
        "#Los índices de filas y columnas por defecto son números enteros empezando desde 0.\n",
        "pd.DataFrame([(10, 20), (30, 40)] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF2CkMPXTr3e"
      },
      "source": [
        "**3.  Diccionarios de *Python***: El constructor también admite diccionarios de *Python* como argumento para su definición. Al recibir este tipo de dato, las llaves del diccionario se interpretan como el índice de las *columnas* y sus valores asociados como el contenido de cada columna, en forma de estructuras de 1 dimensión como arreglos o listas. Es importante que estas tengan la misma longitud, o se producirá un error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_OPQ3ChT0Ej"
      },
      "source": [
        "data = {\n",
        "   'a' : [1,2,3],\n",
        "   'b' : [10,20,30]\n",
        "}\n",
        "\n",
        "pd.DataFrame(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHGgcqzvUM9n"
      },
      "source": [
        "### **2.3. Atributos**\n",
        "---\n",
        "\n",
        "\n",
        "Los objetos *Series* y *DataFrame* tienen algunos atributos a los que se puede acceder con el símbolo **`.`**. Algunos de estos son heredados de sus objetos internos de *NumPy*. A continuación se muestran algunos de ellos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbq_vGlOUszi"
      },
      "source": [
        "s  = pd.Series(np.random.randn(10),\n",
        "               name = 'mi serie'\n",
        "               )\n",
        "\n",
        "df = pd.DataFrame(np.eye(6,3),\n",
        "                  index = list('abcdef'),\n",
        "                  columns = list('XYZ')\n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG8ziANaVqHs"
      },
      "source": [
        "s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbmfmmQ1Vrwx"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXo69cBhU5CC"
      },
      "source": [
        "* **`values:`** El arreglo de *NumPy* con el contenido del objeto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXmgsRdhVKr8"
      },
      "source": [
        "s.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwwVwCYxVLzv"
      },
      "source": [
        "df.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMJK7GqdU8XD"
      },
      "source": [
        "* **`index`**: El objeto de tipo **`pd.Index`** con el índice de la serie, o el índice de las filas del *DataFrame*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x4ORcXsVcsh"
      },
      "source": [
        "s.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUJ4SXPyVfjD"
      },
      "source": [
        "df.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qVZLZssU8dO"
      },
      "source": [
        "* **`columns` (solo *DataFrame*)**: El objeto de tipo **`pd.Index`** con el índice de las columnas del *DataFrame*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D193uAzmWP9-"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPuk_xipWyuv"
      },
      "source": [
        "* **`name` (solo *Series*)**: Cadena de texto con el nombre que recibe la serie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ_iPvKLWyuw"
      },
      "source": [
        "s.name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YCMxGxLXEZz"
      },
      "source": [
        "Cada fila y cada columna en un *DataFrame* son objetos *Series*. El indexado en *pandas* se verá en detalle en el próximo material. Ahora mismo, para algunas de las funcionalidades presentadas puede ser útil dar un vistazo a la indexación básica de columnas de *pandas*. Esta se realiza como el indexado de diccionarios de *Python*, de la siguiente forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJCgrtsbXgpt"
      },
      "source": [
        "df['X'] # Esto retorna la serie correspondiente a la columna X del DataFrame."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MkT5zzgXD58"
      },
      "source": [
        "type(df['X']) # Una única columna es de tipo Series."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M1l3Xs4WbxO"
      },
      "source": [
        "#### **2.3.1. Atributos heredados de *NumPy***\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Uc7CJaJXKWX"
      },
      "source": [
        "* **`size`**: Tamaño (número de elementos) del arreglo de *NumPy* del contenido del objeto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1l0jpvQXKWc"
      },
      "source": [
        "s.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWp0lEGtXRai"
      },
      "source": [
        "df.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h07syyaEXWBi"
      },
      "source": [
        "* **`shape`**: Tupla con el tamaño de las dimensiones del arreglo de *NumPy* del contenido del objeto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vqr4CBIXWBl"
      },
      "source": [
        "s.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEMgz_GvXWB0"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de8Ov0EJXeU9"
      },
      "source": [
        "* **`dtype | dtypes`**: Tipo del arreglo que representa el contenido del objeto. En DataFrames se usa el atributo **`dtypes`**, que retorna una serie con el tipo de dato de cada columna."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7iwII75XeU-"
      },
      "source": [
        "s.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHhd7XUZXeVA"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aevK_YgaY9f"
      },
      "source": [
        "* **`ndim`**: Retorna el número de dimensiones. Por definición siempre va a retornar $1$ si se llama en *Series* y $2$ si se llama en *DataFrame*. En el caso de arreglos n-dimensionales en *NumPy* es muy útil."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3aAtoHnaY9g"
      },
      "source": [
        "s.ndim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4ZvSzVDaY9j"
      },
      "source": [
        "df.ndim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivSHxh27avYi"
      },
      "source": [
        "* **`T`**: Retorna el *DataFrame* transpuesto. Las filas se convierten en columnas y las columnas en filas. En las *Series*, retorna el mismo objeto. El objeto transpuesto de un *DataFrame* puede ser usado como cualquier objeto *DataFrame*, añadiendo flexibilidad en el tratamiento de los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOeG2gy5avYn"
      },
      "source": [
        "s.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edHMo-_favYw"
      },
      "source": [
        "df.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCSb08nBc2ra"
      },
      "source": [
        "df.T.index #El índice de la tabla transpuesta es el índice de las columnas."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3EY-ofITsDE"
      },
      "source": [
        "## **3. Importar y exportar datos**\n",
        "---\n",
        "*Pandas* permite generar y cargar distintos orígenes de datos para su procesamiento o almacenamiento. Uno de los primeros pasos en un proceso de análisis de datos es la adquisición e integración de dichos datos para su posterior procesamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6NU5aH2l85n"
      },
      "source": [
        "### **3.1. Exportar datos**\n",
        "---\n",
        "\n",
        "En esta guía empezaremos por el proceso de exportación de datos por conveniencia, ya que usaremos los datos generados para explicar el cómo importarlos posteriormente.\n",
        "\n",
        "Los objetos *Series* y *DataFrame* tienen métodos de conveniencia para generar como salida archivos de varios formatos importantes. Estos métodos tienen la estructura **`.to_<>`**, en donde **`<>`** corresponde al nombre del formato deseado. A continuación se presentan los más importantes. Se recomienda consultar la [documentación oficial](https://pandas.pydata.org/docs/user_guide/io.html#io-store-in-csv) si necesita un formato en particular.\n",
        "\n",
        "La mayoría de los métodos expuestos, salvo algunas excepciones, funcionan tanto para *DataFrame* como para *Series*. En este tutorial se enseñarán ejemplos del funcionamiento con *DataFrame*, dado que es el escenario más común en el manejo de tablas externas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoGP8PcgvBx5"
      },
      "source": [
        "#Este ejemplo será usado en el resto de explicaciones.\n",
        "\n",
        "index = list('abcd')\n",
        "columns = list('xyz')\n",
        "\n",
        "data = np.random.randint(10, 99, (4,3))\n",
        "df = pd.DataFrame(data, index = index, columns = columns)\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzZRqp5SoU3B"
      },
      "source": [
        "####  **3.1.1. CSV | `.to_csv`**\n",
        "---\n",
        "Del inglés *Comma-separated values*, *csv* es uno de los formatos de archivos de texto más comunes para el almacenamiento de datos tabulares. Como su nombre lo indica, los elementos son almacenados celda a celda separados por comas (u otros delimitadores, si así se desea) y separando las filas con saltos de líneas. Este método acepta muchos argumentos, que permiten personalizar un formato particular. Estos permiten definir, entre otras cosas:\n",
        "\n",
        "  * El nombre y extensión del archivo generado. (**`path`**)\n",
        "  * Un delimitador distinto a la coma. (**`sep`**)\n",
        "  * La representación para datos faltantes. (**`na_rep`**)\n",
        "  * El formato de los decimales. (**`float_format`**)\n",
        "  * El formato de las fechas. (**`date_format`**)\n",
        "  * Imprimir o no el encabezado y el nombre del indice. (**`header`** | **`index`**)\n",
        "  * Filas y columnas a escribir. (**`columns`** | **`chunksize`**)\n",
        "\n",
        "Lo invitamos a consultar la [especificación](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html) de la función en la documentación oficial para más detalles sobre cómo usar estos argumentos.\n",
        "\n",
        "Todos los argumentos son opcionales, y en caso de faltar *pandas* define un comportamiento por defecto con el formato más común y el recomendado en la mayoría de los casos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIi9jpSDvVmj"
      },
      "source": [
        "#Si no se define una ruta, se escribe en una cadena de texto.\n",
        "df.to_csv()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96_cvsrOvc80"
      },
      "source": [
        "#La extensión no tiene que ser csv (aunque se recomienda)\n",
        "df.to_csv('df_to_csv.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4P6ddgBvjWw"
      },
      "source": [
        "#Se muestran los archivos en el directorio actual con el comando del sistema \"ls\".\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxRni1x5vqYI"
      },
      "source": [
        "#Miramos el contenido del archivo generado con el comando del sistema \"cat\".\n",
        "!cat df_to_csv.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5TKZZbZwps7"
      },
      "source": [
        "####  **3.1.2. Hojas de cálculo | `.to_excel`**\n",
        "---\n",
        "Otro de los formatos más comunes es el formato del software *Microsoft Office Excel* (o su alternativa abierta *LibreOffice* con documentos en formato .*odf*), que permite disponer de datos tabulares en hojas de cálculo. Existen muchos datos almacenados en este formato, y suele ser requisito del proceso utilizarlo. *Pandas* permite generar y cargar archivos en este formato, ofreciendo opciones de personalización específicas. Algunas de estas son:\n",
        "\n",
        "  * El nombre y extensión del archivo generado. (**`excel_writer`**)\n",
        "  * El nombre de la hoja de cálculo. (**`sheet_name`**)\n",
        "  * Fila y columna en donde empezar a escribir los datos. (**`startrow`** | **`startcol`**)\n",
        "  *  Combinar celdas de índices múltiples. (**`merge_cells`**)\n",
        "\n",
        "Además, comparte argumentos de detalles de formato con otras funciones, como se mencionó previamente.\n",
        "\n",
        "  Lo invitamos a consultar la [especificación](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html) de la función en la documentación oficial para más detalles sobre cómo usar estos argumentos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZyAuWjQjwKL"
      },
      "source": [
        "df.to_excel('df_to_excel.xlsx', 'hoja_ejemplo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8OAjtc4j-hh",
        "cellView": "both"
      },
      "source": [
        "#(SOLO PARA COLAB) Función para descargar el archivo generado.\n",
        "from google.colab import files\n",
        "files.download('df_to_excel.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VCkd1xezcZh"
      },
      "source": [
        "También, puede consultar y descargar los archivos que tiene disponibles en el sistema de archivos de *Google Colab* haciendo clic en el icono de directorio que aparece en la parte izquierda de esta ventana."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgMraioXlar4"
      },
      "source": [
        "####  **3.1.3. JSON | `.to_json`**\n",
        "---\n",
        "Otro formato común es el *.json* (*JavaScript Object Notation*). Este estándar proviene del lenguaje de programación [*JavaScript*](https://developer.mozilla.org/en-US/docs/Web/JavaScript) y es muy similar a la notación usada en los diccionarios de *Python*, pues usa una combinación entre objetos compuestos por parejas de llaves y valores y listas. *JavaScript* es el lenguaje principal en el desarrollo de páginas web. El estándar *JSON* es independiente del lenguaje, y es muy común usarlo para el intercambio de datos.\n",
        "\n",
        "El principal argumento específico de este formato es **`orient`**, que define los detalles del formato de JSON a generar.\n",
        "\n",
        "Al igual que antes, comparte argumentos de detalles de formato con otras funciones.\n",
        "\n",
        "Lo invitamos a consultar la [especificación](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_json.html) de la función en la documentación oficial para más detalles sobre cómo usar estos argumentos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeX6Upt3raAz"
      },
      "source": [
        "#Python tiene soporte para este formato con el módulo json\n",
        "import json\n",
        "\n",
        "def print_json(raw_json):\n",
        "  parsed = json.loads(raw_json)\n",
        "  print(json.dumps(parsed, indent = 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dcfv9oonpwiM"
      },
      "source": [
        "# columns - Retorna un objeto con las columnas como llave y las filas en forma de objeto.\n",
        "\n",
        "s = df.to_json(orient = 'columns')\n",
        "print_json(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfuUezc2orSy"
      },
      "source": [
        "# split - Retorna las columnas, índice y valores por separado\n",
        "\n",
        "s = df.to_json(orient = 'split')\n",
        "print_json(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaVirdFBoysG"
      },
      "source": [
        "# records - Retorna una lista de los registros (filas) en forma de objeto\n",
        "\n",
        "s = df.to_json(orient = 'records')\n",
        "print_json(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbnE1nPIqe7q"
      },
      "source": [
        "# index - Retorna un objeto con los índices como llave y las columnas en forma de objeto.\n",
        "\n",
        "s = df.to_json(orient = 'index')\n",
        "print_json(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO2qBLBSqwue"
      },
      "source": [
        "# values - Retorna únicamente el arreglo de valores.\n",
        "\n",
        "s = df.to_json(orient = 'values')\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycg2toP3q9M-"
      },
      "source": [
        "# table - Formato de tabla con datos descriptivos de su estructura.\n",
        "\n",
        "s = df.to_json(orient = 'table')\n",
        "print_json(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdsxtL5Wq8D5"
      },
      "source": [
        "df.to_json('df_to_json.json') # El orient por defecto es \"columns\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39x_mfURpumd"
      },
      "source": [
        "!cat df_to_json.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqqOM7R6tgAQ"
      },
      "source": [
        "####  **3.1.4. HTML | `.to_html`**\n",
        "---\n",
        "*Pandas* también permite generar tablas **HTML** (*Hyper Text Markup Language*), el formato usado en páginas web, perfecto para presentar los resultados de un análisis o exponer un conjunto de datos.\n",
        "Este formato tiene muchas opciones de personalización definidas en sus argumentos, que corresponden principalmente al estilo generado, además de los argumentos de detalles de formato comunes.\n",
        "\n",
        "Lo invitamos a consultar la [especificación](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_html.html) de la función en la documentación oficial para más detalles sobre cómo usar estos argumentos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JxS1QCsv1kM"
      },
      "source": [
        "import IPython\n",
        "\n",
        "#Función para renderizar HTML en el notebook.\n",
        "\n",
        "def print_HTML(str):\n",
        "  display(IPython.display.HTML(df.to_html()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Wcmam9vsRb"
      },
      "source": [
        "s = df.to_html('df_to_html.html')\n",
        "\n",
        "print_HTML(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lBw6iiZw3zk"
      },
      "source": [
        "####  **3.1.5. LaTeX | `.to_latex`**\n",
        "---\n",
        "En algunas ocasiones, se puede requerir de formatos más específicos que no sean usados posteriormente en otras aplicaciones. Es el caso de *LaTeX*, estándar para la generación de documentos científicos, con notación especial para ecuaciones y personalización de formatos. *Pandas* también permite generar tablas en este formato, listas para añadirse al código fuente del documento para su renderizado.\n",
        "Este método tiene también múltiples opciones de personalización específicas del formato por medio de argumentos.\n",
        "\n",
        "Lo invitamos a consultar la [especificación](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_latex.html) de la función en la documentación oficial para más detalles sobre cómo usar estos argumentos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XchRPwhzwfcU"
      },
      "source": [
        "df.style.to_latex('df_to_latex.tex')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idK0c351ssCw"
      },
      "source": [
        "!cat df_to_latex.tex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZbAdExxzFJ0"
      },
      "source": [
        "####  **3.1.6. Markdown | `.to_markdown`**\n",
        "---\n",
        "Al hablar de formatos de presentación, no podía faltar *Markdown*, formato usado, entre otras cosas, en el renderizado de las celdas de texto de los *Notebook*. *Pandas* permite generar texto que representa el formato de tablas usado en este lenguaje. Es ideal para generar tablas para sus proyectos con *Notebooks* de *Python*, o para plataformas como *GitHub*.\n",
        "La mayoría de sus argumentos corresponde a la especificación de la librería [*tabulate*](https://pypi.org/project/tabulate/), sobre la cual *pandas* define la personalización de las tablas de *Markdown* generadas.\n",
        "\n",
        "Lo invitamos a consultar la [especificación](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_markdown.html) de la función en la documentación oficial para más detalles sobre cómo usar estos argumentos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBacGmg7z2Kk"
      },
      "source": [
        "s = df.to_markdown()\n",
        "\n",
        "s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4zU-mqE0Z3R"
      },
      "source": [
        "from IPython.display import display_markdown, Markdown\n",
        "\n",
        "#Módulo de IPython para imprimir código fuente de markdown.\n",
        "display_markdown(Markdown(s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UGMKvW90s8A"
      },
      "source": [
        "*Pandas* ha dado soporte a una gran variedad de formatos, pero esta guía sería muy extensa si se presentaran en detalle. A continuación, presentamos una lista de los formatos soportados por *pandas* para la generación de tablas a partir de *DataFrames* y *Series*, o de utilidades específicas que le podrían interesar.\n",
        "\n",
        "*  [*Python* Pickle](https://docs.python.org/3/library/pickle.html): [**`.to_pickle`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_pickle.html)\n",
        "*  [*Apache Parquet*](https://parquet.apache.org/): [**`.to_parquet`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_parquet.html)\n",
        "*  [*Hierarchical Data Format*](https://www.hdfgroup.org/solutions/hdf5/): [**`.to_hdf`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_hdf.html)\n",
        "*  [*SQL (Structured Query Language)*](https://docs.sqlalchemy.org/en/13/): [**`.to_sql`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_sql.html)\n",
        "*  [*Feather File Format*](https://arrow.apache.org/docs/python/feather.html): [**`.to_feather`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_feather.html)\n",
        "*  [*Stata dta*](https://www.stata.com/): [**`.to_stata`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_stata.html)\n",
        "*  [*Google Big Query*](https://cloud.google.com/bigquery): [**`.to_gbq`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_gbq.html)\n",
        "*  [Diccionario de *Python*](https://docs.python.org/3/tutorial/datastructures.html#dictionaries): [**`.to_dict`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_dict.html)\n",
        "*  [*NumPy* record](https://numpy.org/devdocs/reference/generated/numpy.recarray.html#numpy.recarray): [**`.to_records`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_records.html)\n",
        "*  Cadena de texto de *Python*: [**`.to_string`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_string.html)\n",
        "*  Copiar al portapapeles: [**`.to_clipboard`**](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_clipboard.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10H3kc449jfG"
      },
      "source": [
        "### **3.2. Importar datos**\n",
        "---\n",
        "\n",
        "*Pandas*, además de generar, brinda soporte para cargar y dar formato a diversos orígenes de datos. Inicialmente, se requiere reunir y entender los datos de interés y, posteriormente, integrarlos en un conjunto sobre el cual hacer actividades propias del análisis de datos.\n",
        "\n",
        "Para esto, *pandas* dispone de la familia de métodos **`pd.read_*`** que, a diferencia de la familia de métodos **`.to_x`**, son llamados desde el módulo **`pd`** en vez que desde un objeto *DataFrame* o *Series*. Existen aún más métodos para la carga de orígenes de datos que aquellos usados en la generación. Se consideran también orígenes remotos, como conjuntos de datos alojados en la web, bases de datos remotas o de APIs específicas para la consulta de datos.\n",
        "\n",
        "Al llamar estos métodos, *pandas* puede retornar objetos de tipo *Series* o de tipo *DataFrame*, dependiendo de las dimensiones del objeto cargado. Le recomendamos que consulte los detalles específicos de cada método de la documentación oficial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thiiheS6_txM"
      },
      "source": [
        "####  **3.2.1. CSV | `pd.read_csv`**\n",
        "\n",
        "---\n",
        "De la misma forma en que generamos un archivo en este formato, *pandas* permite cargarlo en forma de *DataFrame* o *Series*.\n",
        "En este punto, los argumentos de la función se vuelven fundamentales, dados los posibles problemas que se pueden generar al cargar de forma inadecuada un archivo. *Pandas* permite realizar tareas de limpieza de datos, que se verá en detalle en la segunda parte de este material.\n",
        "Algunos de los argumentos más importantes a tener en cuenta a la hora de cargar archivos en formato .csv son:\n",
        "\n",
        "*  **`path`**: Ruta del archivo a cargar. Este argumento es el primero en posición y es obligatorio. Esta ruta no se limita a archivos locales, también se consideran URLs remotas.\n",
        "*  **`sep`**: Separador de los elementos del archivo.\n",
        "*  **`header`**: Posición del header. La fila indicada será interpretada como los nombres de las columnas y se cargarán las filas que le precedan.\n",
        "*  **`names`**: Nombres a usar para las columnas cargadas. La longitud de esta lista/arreglo debe coincidir con el número de columnas.\n",
        "*  **`index_col`**: Posición o posiciones de las etiquetas usadas como índice. Si es una lista se crea un índice múltiple. Si se pasa el valor **`False`** se puede indicar a *pandas* que no use la primera columna como el índice del *DataFrame*.\n",
        "*  **`usecols`**: Subconjunto de las columnas cargadas a usar en la generación del *DataFrame*.  \n",
        "*  **`true_values` | `true_values`**: Caracteres que serán interpretados como valores de verdad **`True`** y **`False`**.\n",
        "\n",
        "*  **`skip_rows` | `skip_footer`**: Filas a saltar desde el inicio y desde el final.\n",
        "*  **`nrows`**: Total de filas a cargar. Especialmente útil para conjuntos de datos grandes en donde no nos interese toda la información.\n",
        "*  **`na_values` | `keep_default_na` | `na_filter`**: Herramientas para el tratamiento de datos faltantes. Muy importante en el proceso de limpieza de datos.\n",
        "\n",
        "Además de estos, existen muchos argumentos usados para la definición del formato de origen como la fecha o los números decimales, ofreciendo una gran variedad de opciones en la lectura de conjuntos de datos.\n",
        "\n",
        "\n",
        "  Lo invitamos a consultar la [especificación](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html#pandas.read_csv) de la función en la documentación oficial para más detalles sobre cómo usar estos argumentos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uXzSQHDb_Hk"
      },
      "source": [
        "> **Nota:** El siguiente ejemplo solo funciona en *Google Colab*, que trae por defecto algunos *datasets* generales. Para hacerlo en local, ubique el archivo a cargar en la misma ruta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPWU-TbHEV2G"
      },
      "source": [
        "# Carga de archivo ubicado en el sistema de archivos de Google Colab.\n",
        "# En este caso se trata del dataset de prueba de alojamientos en el estado de California.\n",
        "\n",
        "df = pd.read_csv('sample_data/california_housing_test.csv')\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63YaCpsbgUpA"
      },
      "source": [
        "# Podemos cargar el archivo generado anteriormente.\n",
        "# Recuerde que tiene que haber ejecutado la celda donde se genera o se producirá un error.\n",
        "\n",
        "df = pd.read_csv('df_to_csv.txt', index_col=0)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzpNsLaIdO81"
      },
      "source": [
        "# La ruta también puede ser remota, como la de una URL.\n",
        "url = 'https://drive.google.com/uc?export=download&id=1sO-OfJ-GT5emHXr6fRXCWFlzsHqL-YdQ'\n",
        "df = pd.read_csv(url)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mjrCk62gqIN"
      },
      "source": [
        "####  **3.2.2. Hojas de cálculo | `pd.read_excel`**\n",
        "---\n",
        "*Pandas* permite cargar hojas de cálculo de los formatos *xls*, *xlsx*, *xlsm*, *xlsb*, *odf*, *ods* y *odt*. Al igual que antes, la ruta especificada puede ser local o remota en forma de URL. Algunos argumentos a considerar son:\n",
        "\n",
        "  * El nombre de la hoja a cargar. (**`sheet_name`**)\n",
        "  * Posición del encabezado. (**`header`**)\n",
        "  * Columnas de la hoja de cálculo a usar. Se pueden definir en formato de letras o rangos de letras, notación usada para etiquetar columnas. Expresiones de la forma 'A', 'A,C:E', entre otros. (**`usecols`**)\n",
        "  *  Tipo de dato interpretado por columna. (**`dtype`**)\n",
        "  *  Número de filas a cargar. (**`nrows`**)\n",
        "\n",
        "Además, comparte argumentos de detalles de formato con otras funciones, como se mencionó previamente.\n",
        "\n",
        "  Lo invitamos a consultar la [especificación](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html) de la función en la documentación oficial para más detalles sobre cómo usar estos argumentos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukh7qQJoj6s2"
      },
      "source": [
        "pd.read_excel('df_to_excel.xlsx', index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvR6kq-_jhzY"
      },
      "source": [
        "La siguiente es una URL con el *dataset* de datos abiertos de cifras de turismo por mes de la ciudad de Bogotá:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvGPkISxiRlp"
      },
      "source": [
        "#URL con dataset de datos abiertos de cifras de turismo de la ciudad de Bogotá\n",
        "\n",
        "url = 'https://github.com/JuezUN/datasets/blob/master/cifras_turismobog_2018.xlsx?raw=true'\n",
        "\n",
        "df = pd.read_excel(url,\n",
        "              sheet_name = 'Número de Turistas', #Hoja de cálculo a cargar.\n",
        "              header = 8,  #Posición del encabezado\n",
        "              usecols = 'A:D',  #Usar las primeras 5 columnas\n",
        "              nrows = 48\n",
        "            )\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVGdzVw5gqIP"
      },
      "source": [
        "####  **3.2.3. JSON | `pd.read_json`**\n",
        "---\n",
        "En la sección anterior se discutían los métodos para almacenar un objeto mediante el argumento **`orient`**, y se recuerda pues es importante al definir la forma en que se va a cargar un archivo codificado con este estándar en *pandas*. Además de este, otros argumentos a considerar son:\n",
        "\n",
        "\n",
        "  *  Tipo de objeto (*Series* o *DataFrame*) a recuperar. ( **`typ`**)\n",
        "  *  Opciones de formato de fechas específicos de este estándar  (**`convert_dates`** |  **`keep_default_dates`**)\n",
        "\n",
        "Al igual que antes, comparte argumentos de detalles de formato con otras funciones.\n",
        "\n",
        "Lo invitamos a consultar la [especificación](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html) de la función en la documentación oficial para más detalles sobre cómo usar estos argumentos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcE_Ghz5wVv-"
      },
      "source": [
        "df = pd.read_json('df_to_json.json')\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc7Rgl10wmg3"
      },
      "source": [
        "El siguiente ejemplo se realizará con el *dataset* del ejemplo del Cuarteto de Anscombe, cargado por defecto en Google Colab y explorado en la **Unidad 4**.\n",
        "\n",
        "> **Nota:** Si está trabajando en local, recuerde descargar y ubicar apropiadamente el *dataset*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XtalDG9wANZ"
      },
      "source": [
        "#Primero debemos ver en qué formato se encuentra\n",
        "!cat sample_data/anscombe.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwkunIStxLQI"
      },
      "source": [
        "df = pd.read_json('sample_data/anscombe.json', orient = 'records')\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lENI-UDygqIQ"
      },
      "source": [
        "####  **3.2.4. HTML | `pd.read_html`**\n",
        "---\n",
        "Este método permite leer páginas web (usando los protocolos *http*, *ftp* y *file* de URL) en busca de tablas HTML, que son retornadas en una lista de objetos *DataFrame*. Algunos argumentos de interés son:\n",
        "\n",
        "  *  Cadena de texto o expresión regular a buscar en el contenido de las tablas. Si se especifica, solo las tablas que cumplan con esta condición serán cargadas. (**`match`**)\n",
        "\n",
        "  * Etiquetas o atributos HTML usados para identificar una tabla en particular. (**`attrs`**)\n",
        "\n",
        "Lo invitamos a consultar la [especificación](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_html.html) de la función en la documentación oficial para más detalles sobre cómo usar estos argumentos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAJCeeFLyB4K"
      },
      "source": [
        "# Conjunto de datos de abanderados de los juegos olímpicos de Río de Janeiro 2016.\n",
        "dfs = pd.read_html('https://es.wikipedia.org/wiki/Anexo:Abanderados_en_la_ceremonia_de_apertura_de_los_Juegos_Ol%C3%ADmpicos_de_R%C3%ADo_de_Janeiro_2016')\n",
        "\n",
        "# Recuerde que la función retorna una lista con todas las tablas, así solo se encuentre una.\n",
        "\n",
        "dfs[0] # Accedemos a la primera posición de la lista de DataFrames."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIS3PrzaTsGr"
      },
      "source": [
        "## **4. Combinar y agrupar conjuntos de datos**\n",
        "---\n",
        "\n",
        "Cuando se manejan datos que provienen desde múltiples fuentes, es frecuente enfrentar escenarios en los que se requiera combinarlos con el fin de consolidar el conjunto de datos. Esto puede ser necesario para realizar tareas de limpieza, preparación y análisis sobre el conjunto de variables completo.\n",
        "\n",
        "*pandas* permite realizar esta tarea de varias formas, ofreciendo flexibilidad en la manipulación y estructura de datos con sus objetos *DataFrame* y *Series*.\n",
        "\n",
        "A continuación se presentan los métodos principales para la combinación de datos en *pandas*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPhGEx9IPEFs"
      },
      "source": [
        "#### **4.1. Combinación de datos**\n",
        "---\n",
        "* **`pd.concat`**: *Pandas* dispone de un método de alto nivel para concatenar objetos *DataFrame* y *Series* de manera secuencial. Similarmente al método **`concatenate`** de *NumPy*, se puede realizar esta concatenación en cualquiera de los dos ejes o *axis* posibles. ($0$ para filas y $1$ para columnas).\n",
        "Al ser de alto nivel, los objetos se pasan como primer argumento en una colección tipo lista o tupla.\n",
        "\n",
        "  Algunos argumentos adicionales a tener en cuenta son:\n",
        "\n",
        "  *  Definir si conservar o no todos los registros, o sólo a aquellos que son producto de la intersección de los índices de todos los objetos. (**`join`**)   \n",
        "  *  Decidir si respetar el índice de los objetos de entrada, o crear un índice de enteros que empiece en 0. (**`ignore_index`**)\n",
        "  *  Decidir si ordenar o no el eje que no es concatenado.   (**`sort`**)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0WEMbwq2ewZ"
      },
      "source": [
        "a = pd.Series([10,11,12], name = 'a')\n",
        "\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qDAGrC129FY"
      },
      "source": [
        "b = pd.Series([5,4,3], name = 'b')\n",
        "\n",
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKN2gNUC3Cnm"
      },
      "source": [
        "pd.concat([a, b]) # Por defecto se concatena por filas."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngq8HpFT3o0k"
      },
      "source": [
        "pd.concat([a, b], axis = 1) # Los nombres (atributo name) definen el nombre de la columna."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI4a-lhg3yjC"
      },
      "source": [
        "df_a = pd.DataFrame(np.eye(3))\n",
        "\n",
        "df_a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoiWSsG44Arv"
      },
      "source": [
        "df_b = pd.DataFrame(np.full((3,2), -1))\n",
        "\n",
        "df_b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBewO-W64Djd"
      },
      "source": [
        "pd.concat([df_a, df_b], ignore_index= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i3utaZW4KRT"
      },
      "source": [
        "pd.concat([df_a, df_b], axis = 1, ignore_index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tb0S-tbF03h"
      },
      "source": [
        " * **`df.assign`**: Otro método para combinar *Series* u otros objetos similares y añadir su contenido a un *DataFrame* existente en forma de columnas. Los datos permitidos para construir columnas con el método **`assign`** son:\n",
        "\n",
        "  * Objetos *Series*.\n",
        "  * Listas y tuplas de *Python*.\n",
        "  * Arreglos de *NumPy*\n",
        "  * Valores escalares.\n",
        "  * Valores invocables como funciones o clases.\n",
        "\n",
        "Todos los argumentos ingresados al método se interpretan como columnas nuevas a ser creadas.\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnKhwC1BBM67"
      },
      "source": [
        "df = pd.DataFrame({'a' : [1, 2, 3],\n",
        "                   'b' : [4, 5, 6],\n",
        "                   'c' : [7, 8, 9]})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKwUqj69BhyX"
      },
      "source": [
        "serie = pd.Series(['a', 'b', 'c'])\n",
        "lista = [-1] * 3\n",
        "arreglo = np.linspace(0, 1, 3)\n",
        "escalar = 100\n",
        "función = lambda x : x['a'] + x['b']\n",
        "\n",
        "df.assign(d = serie,\n",
        "          e = lista,\n",
        "          f = arreglo,\n",
        "          g = escalar,\n",
        "          h = función)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9vtCx9GDbbC"
      },
      "source": [
        "# El objeto original no se modifica. Recuerde reasignar.\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy2HT54-DhDJ"
      },
      "source": [
        "df = df.assign(d = serie,\n",
        "          e = lista,\n",
        "          f = arreglo,\n",
        "          g = escalar,\n",
        "          h = función)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5okWE72SF0-v"
      },
      "source": [
        "* **`df.merge`**: Este método permite combinar el contenido de dos *DataFrame*. Los valores de la columna indicada, que correspondan en ambos objetos, formarán una nueva fila con los datos de ambos *DataFrame* originales, combinando los valores de las demás columnas en vez de agregarlos secuencialmente. El método es llamado en el primer *DataFrame*, mientras que el segundo es pasado como el primer argumento.\n",
        "\n",
        "  Algunos de sus argumentos son:\n",
        "\n",
        "  * **`how`**: Este argumento define qué valores se van a conservar. Tiene 4 opciones, inspiradas en los *join* de SQL.\n",
        "  * **`outer`**: Se conservan todos los elementos.\n",
        "  * **`inner`**: Se conservan solo los elementos que estén en ambos *DataFrame*.\n",
        "  * **`left`**: Se conservan todos los elementos del *DataFrame* izquierdo.\n",
        "  * **`right`**: Se conservan todos los elementos del *DataFrame* derecho.\n",
        "  * **`on` | `left_on` | `right_on`**: Nombre de la columna a combinar. Se puede definir nombres distintos por cada *DataFrame*.\n",
        "\n",
        "  * **`left_index` | `right_index`**: Utilizar el índice en vez de una columna.\n",
        "  * **`suffixes` | `indicator`**: Generar columnas con información general de la combinación, como el origen de la columna o el método usado.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HklBJfMTve_B"
      },
      "source": [
        "df_izq = pd.DataFrame(\n",
        "    {\n",
        "     'a' : ['a0', 'a1', 'a2'],\n",
        "     'b' : ['b0', 'b1', 'b2']\n",
        "    }\n",
        ")\n",
        "\n",
        "df_izq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5LAX8aO-Vhg"
      },
      "source": [
        "df_der = pd.DataFrame(\n",
        "    {\n",
        "     'a' : ['a1', 'a2', 'a3'],\n",
        "     'c' : ['c1', 'c2', 'c3']\n",
        "    }\n",
        ")\n",
        "df_der"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHbsDYfU-iIN"
      },
      "source": [
        "# Por defecto el método es \"inner\"\n",
        "df_izq.merge(df_der, on = 'a') # Se une con respecto a la columna 'a' en ambas tablas."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaOrnni2AAuv"
      },
      "source": [
        "df_izq.merge(df_der, on = 'a', how = 'outer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK02PVtkAKAt"
      },
      "source": [
        "df_izq.merge(df_der, on = 'a', how = 'left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN9PGQ5yAQFE"
      },
      "source": [
        "df_izq.merge(df_der, on = 'a', how = 'right')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF6Xh93UAfD0"
      },
      "source": [
        "df_der = pd.DataFrame(\n",
        "  {\n",
        "    'col_a' : ['a1', 'a2', 'a3'],\n",
        "    'b' : ['B1', 'B2', 'B3']\n",
        "  }\n",
        ")\n",
        "df_der"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V99Zsy8hAys0"
      },
      "source": [
        "#Cuando se encuentran registros solapados se crean columnas aparte con sufijos por cada tabla.\n",
        "df_izq.merge(df_der,\n",
        "              left_on = 'a',      # Columna usada en la tabla izquierda.\n",
        "              right_on = 'col_a', # Columna usada en la tabla derecha.\n",
        "              how = 'outer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_vQPkSRBP8J"
      },
      "source": [
        "df_izq.merge(df_der,\n",
        "              left_on = 'a',      # Columna usada en la tabla izquierda.\n",
        "              right_on = 'col_a', # Columna usada en la tabla derecha.\n",
        "              how = 'outer',\n",
        "              suffixes = ('_izq', '_der'), # Sufijos para columnas solapadas.\n",
        "              indicator = True # Indicador (columna \"_merge\") de origen de cada fila.\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soOJOASlGCfv"
      },
      "source": [
        "* **`df.join`**: Este método comparte la funcionalidad de **`merge`**, pero acercándose más al estilo de combinación de tablas SQL, que realiza combinaciones en los índices de cada tabla. Si bien se puede obtener el mismo resultado con **`merge`** y los argumentos **`left_index`** y **`right_index`**, se recomienda usar **`join`** para simplificar la tarea."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbYC0B-7C9bZ"
      },
      "source": [
        "df_izq = pd.DataFrame(\n",
        "    {\n",
        "     'a' : ['a0', 'a1', 'a2'],\n",
        "     'b' : ['b0', 'b1', 'b2']\n",
        "    },\n",
        "    index = ['i0', 'i1', 'i2'] #Usamos el mismo ejemplo, pero con índice distinto.\n",
        ")\n",
        "\n",
        "df_izq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g4d0kShDRUz"
      },
      "source": [
        "df_der = pd.DataFrame(\n",
        "    {\n",
        "     'c' : ['c1', 'c3', 'c4'],\n",
        "     'd' : ['d1', 'd3', 'd4']\n",
        "    },\n",
        "    index = ['i1', 'i3', 'i4']\n",
        ")\n",
        "\n",
        "df_der"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Wt89sWDlSE"
      },
      "source": [
        "# Usando merge\n",
        "df_izq.merge(df_der, left_index = True, right_index = True, how = 'outer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajNwb1sgD1Ty"
      },
      "source": [
        "# El mismo resultado con join\n",
        "df_izq.join(df_der, how = 'outer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib5Jns5zWH2c"
      },
      "source": [
        "El objeto pasado como argumento puede ser un objeto *Series* con nombre. El nombre es necesario pues corresponde al nombre de la columna creada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEcHu7o3ETUz"
      },
      "source": [
        "sr = pd.Series([0, 1, 0, 0],\n",
        "                 index = ['i0', 'i1', 'i3', 'i4'],\n",
        "                 name = 's')\n",
        "\n",
        "df_der.join(sr) # En join el método por defecto es \"left\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2kBeUhYU-hK"
      },
      "source": [
        "df_der2 = pd.DataFrame(\n",
        "    {\n",
        "      'b' : ['b1', 'b3', 'b4'],\n",
        "      'c' : ['c1', 'c3', 'c4']\n",
        "    },\n",
        "    index = ['i1', 'i3', 'i4']\n",
        ")\n",
        "\n",
        "df_izq.join(df_der2,\n",
        "             how = 'outer',\n",
        "             lsuffix = '_izq', # Los sufijos se especifican por separado.\n",
        "             rsuffix = '_der'\n",
        "             )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiJbQt-sEX3_"
      },
      "source": [
        "El método **`join`** también permite hacer múltiples combinaciones en un solo llamado, pasando como argumento del método una lista de *DataFrames*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_isk84t5Wn1t"
      },
      "source": [
        "df_der2 = pd.DataFrame(\n",
        "    {\n",
        "      'e' : ['e0', 'e3', 'e4'],\n",
        "      'f' : ['f0', 'f3', 'f4']\n",
        "    },\n",
        "    index = ['i0', 'i3', 'i4']\n",
        ")\n",
        "\n",
        "\n",
        "df_izq.join([df_der, df_der2],\n",
        "             how = 'outer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVmjPDly3Vt-"
      },
      "source": [
        "#### **4.2. Agrupación de datos con `df.groupby`**\n",
        "---\n",
        "\n",
        "*Pandas* ofrece métodos para realizar operaciones de agrupación y combinación de datos dentro de un mismo objeto. Estas operaciones consisten en tres fases:\n",
        "\n",
        "*  **Separar** los datos en grupos basándose en algunos criterios.\n",
        "*  **Aplicar** una función a cada grupo. Estas funciones pueden ser de agregación, transformación o filtrado.\n",
        "*  **Combinar** los resultados de la función en una estructura de datos nueva, como un *DataFrame*.\n",
        "\n",
        "\n",
        "Esto es posible con el método **`groupby`**, que realiza un agrupamiento respecto a los criterios definidos en su argumento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9tEvveWc9Je"
      },
      "source": [
        "#Usaremos de nuevo el dataset de ejemplo de Anscombe para este ejemplo.\n",
        "df = pd.read_json('sample_data/anscombe.json', orient = 'records')\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn5jvgo_c8La"
      },
      "source": [
        "# Podemos definir una columna categórica respecto a la cual agrupar.\n",
        "df.groupby('Series')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_kSTd2ie1fE"
      },
      "source": [
        "La agrupación genera un objeto de tipo **`groupby`**, que contiene la información y los métodos necesarios para operar con cada grupo obtenido. Cada grupo es técnicamente un *DataFrame*, aunque para esto se tienen que iterar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7NQxc737QdH"
      },
      "source": [
        "for nombre, grupo in df.groupby('Series'):\n",
        "  print(f'Nombre del grupo: {nombre}')\n",
        "  print(grupo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-4UdJnNC0H5"
      },
      "source": [
        "Si se desea obtener un grupo en particular, puede usar el método **`get_group`**, indicando el nombre del grupo creado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0k4JX0wCzpN"
      },
      "source": [
        "df.groupby('Series').get_group('I')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw2I6XoZ7rP1"
      },
      "source": [
        "También pueden tomarse funciones, que son evaluadas en el índice del objeto. Sin embargo, es más práctico utilizar los métodos propios del objeto para **aplicar** funciones comunes.\n",
        "\n",
        "A continuación se presentan algunos de los métodos más importantes y flexibles definidos para objetos de este tipo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P5v7NCR872g"
      },
      "source": [
        "* **`groupby.apply`**: Este método es el más general para la aplicación de funciones en grupos de un objeto **`groupby`**. Permite aplicar una función en un objeto por cada grupo (un objeto *DataFrame*) calculado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mS-Zv2LAUvp"
      },
      "source": [
        "#Máximo de los elementos en la columna Y de cada grupo.\n",
        "df.groupby('Series').apply(lambda df: df['Y'].max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY417MpJEWgG"
      },
      "source": [
        "def apply_func(df):\n",
        "  '''\n",
        "  Función más compleja que define una fila nueva\n",
        "  con los máximos y mínimos en X y Y de cada grupo.\n",
        "  '''\n",
        "  return pd.Series({\n",
        "       'max_x': df['X'].max(),\n",
        "       'min_x': df['X'].min(),\n",
        "       'max_y': df['Y'].min(),\n",
        "       'min_y': df['Y'].min()\n",
        "   })\n",
        "\n",
        "df.groupby('Series').apply(apply_func)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smIpNmfGFV38"
      },
      "source": [
        "El método **`apply`** está definido también en objetos *DataFrame* y *Series*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdYMHQkMUiKh"
      },
      "source": [
        "# En Series recibe funciones que toman como parámetros valores escalares.\n",
        "\n",
        "s = pd.Series(np.linspace(0,1,11))\n",
        "\n",
        "s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXS_GuohVApw"
      },
      "source": [
        "# Función de números negativos.\n",
        "\n",
        "s.apply(lambda x: -x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ma5rd1lVHFZ"
      },
      "source": [
        "# En DataFrame, el argumento recibe una fila o columna en forma de Series.\n",
        "\n",
        "df = pd.DataFrame(np.random.rand(7,3), columns = list('abc'))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQknLZgpVXkL"
      },
      "source": [
        "df.apply(lambda row: row.sum()) # Por defecto se aplica la función en columnas."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKHBnAzNVlHU"
      },
      "source": [
        "df.apply(lambda row: row.sum(), axis = 1) #El argumento axis = 1 indica que se aplique por filas."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZIdW2IjWCyA"
      },
      "source": [
        "* **`groupby.aggregate|agg`**: Uno de los tipos de aplicación de funciones más importante es la **agregación** que consiste en realizar un cálculo en cada grupo que resuma o represente al grupo completo, como la suma o la media. Para esto, se puede usar el método **`.aggregate`** (o su equivalente **`.agg`**), que acepta como argumento una función de agregación a aplicar en los *DataFrame* definidos en cada grupo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLVfKhZ2s76b"
      },
      "source": [
        "En el siguiente video presentamos un ejemplo de su aplicación, con una tabla ficticia de datos de una competición deportiva internacional.\n",
        "\n",
        "> **Nota:** Las funciones **`agg`** y **`aggregate`** también están disponibles como métodos de *DataFrame* y *Series*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTlEyDXoVxVn",
        "cellView": "form"
      },
      "source": [
        "#@title **4.2.1. Agrupación y agregación (animación)**\n",
        "from IPython.display import IFrame\n",
        "\n",
        "IFrame(src=\"https://drive.google.com/file/d/15bQjLpq4Dfvb_IkwYs5pZzg1mEiL7OcS/preview\",\n",
        "       width='768px', height='432px')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n6SwxolZKog"
      },
      "source": [
        "df = pd.DataFrame({\n",
        "      'País'      : ['COL', 'BRA', 'VEN', 'COL', 'VEN', 'COL'],\n",
        "      'Edad'      : [20, 24, 30, 34, 25, 35],\n",
        "      'Medallas'  : [5, 14, 4, 4, 10, 0]\n",
        "   },\n",
        "   index = ['1001', '1002','1003','1004','1005','1006']\n",
        "   )\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4gHLrPPb7sr"
      },
      "source": [
        "El método **`agg`** acepta funciones puntuales como **`apply`**, además de permitir ingresar una o varias funciones de agregación por columna mediante un diccionario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUUPcao2bIwO"
      },
      "source": [
        "# Tabla que refleja la edad máxima y el total de medallas por país.\n",
        "\n",
        "df.groupby('País').agg({'Edad' : max, 'Medallas' : sum})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzL7stA4cSNX"
      },
      "source": [
        "# Se pueden agregar varias funciones por columna.\n",
        "\n",
        "df.groupby('País').agg({'Edad' : [min, max], 'Medallas' : sum})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O27A5YxMcchR"
      },
      "source": [
        "# El mismo resultado se puede conseguir con una función y el método apply.\n",
        "\n",
        "def resumen_deportivo(df):\n",
        "  return pd.Series({\n",
        "                      'Edad (max)': df['Edad'].max(),\n",
        "                      'Medallas (sum)': df['Medallas'].sum()\n",
        "                    })\n",
        "\n",
        "df.groupby('País').apply(resumen_deportivo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r5hSQAz6d-g"
      },
      "source": [
        "## **Recursos adicionales**\n",
        "---\n",
        "\n",
        "En este material se consideran algunas de las funciones más comunes, pero quedan muchas otras fuera de alcance. Lo invitamos a que consulte la [documentación oficial](https://pandas.pydata.org/pandas-docs/stable/reference/index.html), y en especial la [Guía de usuario](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html) de *pandas*.\n",
        "\n",
        "Además, a continuación se presenta una lista de recursos adicionales que le podrán ser de utilidad:\n",
        "\n",
        "*  [University of California San Diego. Coursera - Machine Learning With Big Data](https://www.coursera.org/learn/big-data-machine-learning)\n",
        "*  [Data vedas - Exploración y preparación de los datos](https://www.datavedas.com/data-exploration-and-preparation/)\n",
        "*  [Kaggle - Pandas](https://www.kaggle.com/learn/pandas)\n",
        "*  [CodeCademy - Learn Data Analysis with Pandas](https://www.codecademy.com/learn/data-processing-pandas)\n",
        "*  [University of Michigan. Coursera - Applied Data Science with Python Specialization](https://www.coursera.org/specializations/data-science-python)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4VavQ3wgMGo"
      },
      "source": [
        "## **Créditos**\n",
        "---\n",
        "\n",
        "* **Profesor:** [Felipe Restrepo Calle](https://dis.unal.edu.co/~ferestrepoca/)\n",
        "* **Asistentes docentes:**\n",
        "  - Alberto Nicolai Romero Martínez\n",
        "  - Miguel Angel Ortiz Marín\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ]
}