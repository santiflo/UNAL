{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a11edf16",
      "metadata": {
        "id": "a11edf16"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1YjAWn06OMcVhlyixBZBDnY17rnn7Otg5\" width=\"100%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42e3a44b",
      "metadata": {
        "id": "42e3a44b"
      },
      "source": [
        "# Dataframes de Dask\n",
        "\n",
        "En este notebook veremos una introducción práctica al procesamiento distribuido con la librería `dask`, primero lo instalaremos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77fe5a09",
      "metadata": {
        "id": "77fe5a09"
      },
      "outputs": [],
      "source": [
        "!pip install dask[complete] h5py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b16a069",
      "metadata": {
        "id": "8b16a069"
      },
      "source": [
        "## **1. ¿Qué son los DataFrames de Dask?**\n",
        "---\n",
        "\n",
        "Los DataFrames de `dask` son una estructura de datos tabular que está compuesta de múltiples DataFrames de `pandas`:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1YU3e3pTdLNsmsfinUCPnGSN2PK_zrAUL\" width=\"50%\">\n",
        "\n",
        "Este tipo de estructura de datos permite coordinar, paralelizar y distribuir series y dataframes de `pandas` dandonos una forma de uso muy similar a los `pd.DataFrame`.\n",
        "\n",
        "Generalmente usamos los `DataFrame` de `dask` cuando:\n",
        "\n",
        "* Tenemos conjuntos de datos grandes que no caben en la memoria RAM.\n",
        "* Queremos acelerar operaciones sobre datasets usando varios núcleos de un computador o varios nodos.\n",
        "\n",
        "Veamos los detalles de este tipo de estructuras, primero importamos el módulo para usar DataFrames:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4d23608",
      "metadata": {
        "id": "c4d23608"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import dask.dataframe as dd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3bba134",
      "metadata": {
        "id": "f3bba134"
      },
      "source": [
        "## **2. Creación**\n",
        "---\n",
        "\n",
        "Existen diversas funciones para crear `DataFrames` en `dask`, veamos algunos casos:\n",
        "\n",
        "* `from_pandas`: podemos crear un `DataFrame` de `dask` desde un `pd.DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34e308a9",
      "metadata": {
        "id": "34e308a9"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(\n",
        "        {\n",
        "            \"A\": np.random.uniform(-1, 1, 100),\n",
        "            \"B\": np.random.randint(1, 5, 100)\n",
        "            },\n",
        "        )\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4d86e77",
      "metadata": {
        "id": "f4d86e77"
      },
      "source": [
        "Creamos la tabla en `dask`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d3be713",
      "metadata": {
        "id": "9d3be713"
      },
      "outputs": [],
      "source": [
        "df_dask = dd.from_pandas(df, npartitions=2)\n",
        "df_dask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f7bf848",
      "metadata": {
        "id": "7f7bf848"
      },
      "source": [
        "El parámetro `n_partitions` nos permite especificar en cuántos chunks se divide el `DataFrame`, también puede usar el parámetro `chunks` de forma equivalente a los arreglos de `dask`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "194241dc",
      "metadata": {
        "id": "194241dc"
      },
      "outputs": [],
      "source": [
        "df_dask = dd.from_pandas(df, chunksize=10)\n",
        "df_dask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ab21aa8",
      "metadata": {
        "id": "9ab21aa8"
      },
      "source": [
        "* `from_array`: permite crear un `DataFrame` a partir de un arreglo de `numpy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21bc8853",
      "metadata": {
        "id": "21bc8853"
      },
      "outputs": [],
      "source": [
        "df = dd.from_array(\n",
        "        np.random.uniform(0, 1, size=(10, 2)),\n",
        "        columns=[\"grade\", \"value\"],\n",
        "        )\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f540fbe5",
      "metadata": {
        "id": "f540fbe5"
      },
      "source": [
        "Como vimos, es posible crear `DataFrames` de `dask` desde multiples estructuras de datos clásicas de _Python_, no obstante, estos enfoques requieren que los datos estén en la memoria RAM (lo cual no es posible con grandes cantidades de datos). Por ello, normalmente estaremos creando `DataFrames` de `dask` por medio de funciones de lectura para distintos tipos de formatos de datos tabulares, algunos ejemplos comunes son:\n",
        "\n",
        "* `dd.read_csv`: funciona igual que la función de `pandas` (tiene los mismos parámetros), no obstante, agrega el parámetro `blocksize` (tamaño de las particiones en bytes) para controlar las particiones.\n",
        "* `dd.read_json`: funciona igual que la función de `pandas` y también agrega el parámetro `blocksize`.\n",
        "* `dd.read_sql_query`: funciona igual que la función `pd.read_sql` pero agrega el parámetro `npartitions` para controlar el número de particiones.\n",
        "* `dd.read_parquet`: permite cargar archivos en formato `parquet`, el cual es un tipo de formato que ya viene particionado y resulta ser muy compatible con `dask` como lo veremos más adelante.\n",
        "\n",
        "Veamos un ejemplo donde cargamos un conjunto de datos desde `dask`, usaremos el conjunto de datos [Netflix Data: Cleaning, Analysis and Visualization](https://www.kaggle.com/datasets/ariyoomotade/netflix-data-cleaning-analysis-and-visualization), el cual incluye información acerca del contenido añadido a la plataforma de streaming *Netflix* entre el $2008$ y el $2021$. Está conformado por 10 columnas, las cuales son:\n",
        "\n",
        "* `show_id`: corresponde a la llave primaria de la tabla. Tiene un formato establecido el cual corresponde a una <i>s</i> seguida de un número en secuencia, por ejemplo: s34.\n",
        "* `type`: indica el tipo de show ofrecido (Película o Serie).\n",
        "* `title`: señala el nombre de la serie o la película.\n",
        "* `director`: indica el nombre de quién dirigió la película o serie.\n",
        "* `country`: indica el lugar de producción del show.\n",
        "* `date_added`: muestra la fecha de publicación de la serie o película en la plataforma con el formato <i>MM, DD, AAAA</i>.\n",
        "* `release_year`: muestra el año de publicación original de la película o serie.\n",
        "* `rating`: muestra las calificaciones o el nivel de conveniencia de la película según su contenido, por ejemplo: PG-13, TV-PG, etc.\n",
        "* `duration`: corresponde a la duración en minutos en el caso de las películas y la cantidad de temporadas en el caso de las series.\n",
        "* `listed_in`: indica el género o categoría donde se clasifica la serie o película dentro de la plataforma.\n",
        "\n",
        "Primero, descargamos el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e00777d1",
      "metadata": {
        "id": "e00777d1"
      },
      "outputs": [],
      "source": [
        "!wget 'https://drive.google.com/uc?export=view&id=1B0Cgf1mlulbRCvbZ5DytUCI1FI6UCP9u' -O 'netflix2.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d27d1deb",
      "metadata": {
        "id": "d27d1deb"
      },
      "source": [
        "Ahora, lo descomprimimos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bf90945",
      "metadata": {
        "id": "0bf90945"
      },
      "outputs": [],
      "source": [
        "![[ -d 'netflix2.parquet' ]] && rm -rf 'netflix2.parquet'\n",
        "!unzip 'netflix2.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39cebde0",
      "metadata": {
        "id": "39cebde0"
      },
      "source": [
        "## **3. Apache Parquet**\n",
        "---\n",
        "\n",
        "En este caso, el conjunto de datos se encuentra en formato `parquet`, se trata de un formato de código abierto, orientado a columnas (como _Cassandra_) que está pensado para un almacenamiento eficiente y de rápida lectura:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Bjig-W9_-0JJ_I6IYxZa6oJkMKTpla4E\t\" width=\"70%\">\n",
        "\n",
        "Este formato tiene tres componentes:\n",
        "\n",
        "* **Header**: guarda información general del archivo (por ejemplo, el id de la partición que estamos manejando).\n",
        "* **Data block**: almacena la información como chunks columnares de los datos.\n",
        "* **Footer**: almacena metadatos del archivo (por ejemplo, fecha de creación, versión del formato, esquema de columnas, tipos, entre otros).\n",
        "\n",
        "Este formato es muy popular hoy en día para almacenar conjuntos de datos por los siguientes motivos:\n",
        "\n",
        "* Almacena los tipos de cada columna.\n",
        "* Es particionado, lo cual facilita la tranferencia de datos.\n",
        "* Se lee bastante rápido, lo cual hace que sea preferido sobre formatos clásicos como `csv` o `excel`.\n",
        "\n",
        "El formato `parquet` es normalmente usado para crear _Data Lakes_. Veamos cómo cargar este conjunto de datos con `dask`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d40cdfe",
      "metadata": {
        "id": "2d40cdfe"
      },
      "outputs": [],
      "source": [
        "df = dd.read_parquet(\"netflix2.parquet\")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da9af3c9",
      "metadata": {
        "id": "da9af3c9"
      },
      "source": [
        "Como se puede ver, el archivo ya trae `20` particiones (nativas del formato `parquet`), veamos algunos detalles de los `DataFrames` de `dask` con este conjunto de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "383e21c4",
      "metadata": {
        "id": "383e21c4"
      },
      "source": [
        "## **4. Atributos y Propiedades**\n",
        "---\n",
        "\n",
        "Los `DataFrame` de `dask` tienen una forma de uso muy parecida a los de `pandas`, sin embargo, en `dask` no tenemos los resultados cargados directamente en la memoria RAM. Funcionan de una forma muy equivalente a los arreglos de `dask` y terminan siendo promesas de `DataFrame` de `pandas`. Veamos los atributos más comunes que se usan en `dask`:\n",
        "\n",
        "* `columns`: permite obtener el nombre de las columnas del `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8d4ef1c",
      "metadata": {
        "id": "a8d4ef1c"
      },
      "outputs": [],
      "source": [
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ade3cb61",
      "metadata": {
        "id": "ade3cb61"
      },
      "source": [
        "* `dtypes`: permite extraer los tipos que tiene cada columna del `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d57d2768",
      "metadata": {
        "id": "d57d2768"
      },
      "outputs": [],
      "source": [
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50aa3d57",
      "metadata": {
        "id": "50aa3d57"
      },
      "source": [
        "* `shape`: permite extraer el tamaño del `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b31fbb1c",
      "metadata": {
        "id": "b31fbb1c"
      },
      "outputs": [],
      "source": [
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7e870f1",
      "metadata": {
        "id": "f7e870f1"
      },
      "source": [
        "Note que el resultado tiene un tipo `Delayed` que no es directamente un número, esto se debe a que `dask` no conoce qué tamaño va a tener el arreglo en memoria (no ha sido cargado). Podemos calcular el tamaño con el método `compute`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "779c7e1a",
      "metadata": {
        "id": "779c7e1a"
      },
      "outputs": [],
      "source": [
        "print(df.shape[0].compute())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bed4cc7c",
      "metadata": {
        "id": "bed4cc7c"
      },
      "source": [
        "* `npartitions`: permite obtener el número de particiones del `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12ac2a5e",
      "metadata": {
        "id": "12ac2a5e"
      },
      "outputs": [],
      "source": [
        "print(df.npartitions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "301379b6",
      "metadata": {
        "id": "301379b6"
      },
      "source": [
        "* También podemos acceder a una columna específica por medio de la notación punto, por ejemplo, podemos obtener una serie de `Dask` al acceder a la propiedad `title` (nombre de columna) del `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1faa292b",
      "metadata": {
        "id": "1faa292b"
      },
      "outputs": [],
      "source": [
        "col = df.title\n",
        "col"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683dce4b",
      "metadata": {
        "id": "683dce4b"
      },
      "source": [
        "## **5. Métodos**\n",
        "---\n",
        "\n",
        "Los métodos de los `DataFrames` en `dask` tratan de ser lo más cercanos posibles a los métodos en `pandas`.\n",
        "\n",
        "Al igual que con los arreglos de `dask`, hay un método clave que nos permite evaluar los resultados directamente en memoria, por ejemplo, el siguiente código extrae los primeros `5` registros usando el método `head`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "010cca8c",
      "metadata": {
        "id": "010cca8c"
      },
      "outputs": [],
      "source": [
        "res = df.head(5)\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3e18902",
      "metadata": {
        "id": "c3e18902"
      },
      "source": [
        "El resultado obtenido es un `DataFrame` de `pandas`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91886e18",
      "metadata": {
        "id": "91886e18"
      },
      "outputs": [],
      "source": [
        "print(type(res))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2166af9b",
      "metadata": {
        "id": "2166af9b"
      },
      "source": [
        "Otro método específico en `dask` es `repartition`, el cual permite cambiar el número de particiones de un `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81c4fe77",
      "metadata": {
        "id": "81c4fe77"
      },
      "outputs": [],
      "source": [
        "df2 = df.repartition(npartitions=40)\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4a606fb",
      "metadata": {
        "id": "f4a606fb"
      },
      "source": [
        "Veamos algunos de los métodos más comunes que se usan con los `DataFrames` de `dask`:\n",
        "\n",
        "* `info`: permite obtener una descripción muy general del `DataFrame` (mucho más compacta que la de `pandas` ya que no hemos cargado el conjunto de datos completo):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdbfd9be",
      "metadata": {
        "id": "cdbfd9be"
      },
      "outputs": [],
      "source": [
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2a00de2",
      "metadata": {
        "id": "f2a00de2"
      },
      "source": [
        "* `describe`: permite obtener estadísticas generales del conjunto de datos, recuerde que el parámetro `include` funciona como en `pandas` y permite seleccionar los tipos de columnas a describir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f037391b",
      "metadata": {
        "id": "f037391b"
      },
      "outputs": [],
      "source": [
        "desc = df.describe(include=\"all\")\n",
        "desc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "600ac7f8",
      "metadata": {
        "id": "600ac7f8"
      },
      "source": [
        "Debemos evaluarlo para ver el resultado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a9c7cf3",
      "metadata": {
        "id": "9a9c7cf3"
      },
      "outputs": [],
      "source": [
        "desc.compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e317fa8",
      "metadata": {
        "id": "9e317fa8"
      },
      "source": [
        "* `mean`: permite obtener el promedio por columnas del `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c47a440",
      "metadata": {
        "id": "6c47a440"
      },
      "outputs": [],
      "source": [
        "mean = df.mean()\n",
        "print(mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f932952b",
      "metadata": {
        "id": "f932952b"
      },
      "source": [
        "Debemos evaluarlo para ver el resultado (únicamente aplica sobre las columnas numéricas):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92abaf2c",
      "metadata": {
        "id": "92abaf2c"
      },
      "outputs": [],
      "source": [
        "print(mean.compute())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1365ba0b",
      "metadata": {
        "id": "1365ba0b"
      },
      "source": [
        "* `std`: permite obtener la desviación estándar por columnas del `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d153767f",
      "metadata": {
        "id": "d153767f"
      },
      "outputs": [],
      "source": [
        "std = df.std()\n",
        "print(std)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50dc5e54",
      "metadata": {
        "id": "50dc5e54"
      },
      "source": [
        "Debemos evaluarlo para ver el resultado (únicamente aplica sobre las columnas numéricas):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1443864",
      "metadata": {
        "id": "f1443864"
      },
      "outputs": [],
      "source": [
        "print(std.compute())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ee2c12f",
      "metadata": {
        "id": "2ee2c12f"
      },
      "source": [
        "* `value_counts`: permite obtener un recuento de valores en una columna dada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dac4a5d",
      "metadata": {
        "id": "5dac4a5d"
      },
      "outputs": [],
      "source": [
        "type_counts = df.type.value_counts()\n",
        "print(type_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "853dd8fa",
      "metadata": {
        "id": "853dd8fa"
      },
      "source": [
        "Debemos evaluarlo para ver el resultado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb0c7570",
      "metadata": {
        "id": "cb0c7570"
      },
      "outputs": [],
      "source": [
        "print(type_counts.compute())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93d60774",
      "metadata": {
        "id": "93d60774"
      },
      "source": [
        "* `rename`: permite cambiar el esquema del `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4992b6ef",
      "metadata": {
        "id": "4992b6ef"
      },
      "outputs": [],
      "source": [
        "df2 = df.rename(columns={\"title\": \"titulo\"})\n",
        "print(df2.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "026f8274",
      "metadata": {
        "id": "026f8274"
      },
      "source": [
        "* `astype`: permite cambiar los tipos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeeece23",
      "metadata": {
        "id": "eeeece23"
      },
      "outputs": [],
      "source": [
        "new_col = df.release_year.astype(\"string\")\n",
        "print(new_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3328131",
      "metadata": {
        "id": "d3328131"
      },
      "source": [
        "También funciona sobre varias columnas de un `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d2bead7",
      "metadata": {
        "id": "5d2bead7"
      },
      "outputs": [],
      "source": [
        "df2 = df.astype({\"release_year\": \"string\", \"title\": \"string\"})\n",
        "print(df2.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5622d6ac",
      "metadata": {
        "id": "5622d6ac"
      },
      "source": [
        "* `isna`: permite detectar valores faltantes, por ejemplo, la siguiente celda calcula el número de valores faltantes por columna:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1345e8c0",
      "metadata": {
        "id": "1345e8c0"
      },
      "outputs": [],
      "source": [
        "nas = df.isna().sum()\n",
        "print(nas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d0053a5",
      "metadata": {
        "id": "2d0053a5"
      },
      "source": [
        "Evaluamos el resultado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a492452b",
      "metadata": {
        "id": "a492452b"
      },
      "outputs": [],
      "source": [
        "print(nas.compute())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac26a40d",
      "metadata": {
        "id": "ac26a40d"
      },
      "source": [
        "* `dropna`: permite eliminar valores faltantes, funciona exactamente como lo hace la función de `pandas`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f77e5fb1",
      "metadata": {
        "id": "f77e5fb1"
      },
      "outputs": [],
      "source": [
        "res = df.dropna()\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0cbba99",
      "metadata": {
        "id": "c0cbba99"
      },
      "source": [
        "* `fillna`: permite reemplazar valores faltante, funciona exactamente como lo hace la función de `pandas`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d97d8723",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "d97d8723"
      },
      "outputs": [],
      "source": [
        "res = df.fillna(0)\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cf75bb0",
      "metadata": {
        "id": "1cf75bb0"
      },
      "source": [
        "* `apply`: esta función tiene la misma utilidad que en `pandas`, no obstante, resulta ser bastante importante en `dask` ya que nos permite ejecutar una función de _Python_ de forma distribuida y paralelizada sobre un `DataFrame`, por ejemplo, la siguiente función calcula los dos últimos dígitos del año de publicación de un show:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bf9784b",
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "4bf9784b"
      },
      "outputs": [],
      "source": [
        "def get_digits(year):\n",
        "    return year % 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d41fe368",
      "metadata": {
        "id": "d41fe368"
      },
      "source": [
        "Veamos algunos ejemplos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d01f3f2c",
      "metadata": {
        "id": "d01f3f2c"
      },
      "outputs": [],
      "source": [
        "print(get_digits(2009))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3be0b46",
      "metadata": {
        "id": "e3be0b46"
      },
      "outputs": [],
      "source": [
        "print(get_digits(1996))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9520717",
      "metadata": {
        "id": "f9520717"
      },
      "outputs": [],
      "source": [
        "print(get_digits(2022))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d86d23f2",
      "metadata": {
        "id": "d86d23f2"
      },
      "source": [
        "Podemos aplicarla sobre la columna `release_year` con `dask`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ef0f18",
      "metadata": {
        "id": "88ef0f18"
      },
      "outputs": [],
      "source": [
        "digits = (\n",
        "        df.release_year.apply(get_digits, meta=(\"release_year\", \"int64\")).compute()\n",
        "        )\n",
        "digits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7f39119",
      "metadata": {
        "id": "a7f39119"
      },
      "source": [
        "En este caso, agregamos el parámetro `meta` para dar más información a `dask` sobre el tipo de columna que es `release_year`. Ya que `dask` por defecto trabaja sobre unos tipos inferidos de la carga de datos que pueden ser erróneos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00147230",
      "metadata": {
        "id": "00147230"
      },
      "source": [
        "* `map`: permite mapear una tabla de referencia a una columna:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08544bdd",
      "metadata": {
        "id": "08544bdd"
      },
      "outputs": [],
      "source": [
        "maps = {\"movie\": \"pelicula\", \"tv show\": \"television\"}\n",
        "new_types = df.type.map(maps)\n",
        "new_types"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ac532c1",
      "metadata": {
        "id": "5ac532c1"
      },
      "source": [
        "Veamos el resultado evaluado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2da45bd2",
      "metadata": {
        "id": "2da45bd2"
      },
      "outputs": [],
      "source": [
        "print(new_types.compute())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f291ed1",
      "metadata": {
        "id": "6f291ed1"
      },
      "source": [
        "* `assign`: permite crear nuevas columnas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14212e25",
      "metadata": {
        "id": "14212e25"
      },
      "outputs": [],
      "source": [
        "df2 = df.assign(\n",
        "        new_col = 1,\n",
        "        types_spa = df.type.map(maps)\n",
        "        )\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f85fb8a8",
      "metadata": {
        "id": "f85fb8a8"
      },
      "source": [
        "Veamos los primeros 5 registros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5673b8de",
      "metadata": {
        "id": "5673b8de"
      },
      "outputs": [],
      "source": [
        "df2.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a97479ce",
      "metadata": {
        "id": "a97479ce"
      },
      "source": [
        "* `groupby`: funciona igual que su analogo en `pandas` pero este se ejecuta de forma distribuida:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6e9435a",
      "metadata": {
        "id": "d6e9435a"
      },
      "outputs": [],
      "source": [
        "res = df.groupby(\"type\").agg({\"title\": \"count\"})\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47d40116",
      "metadata": {
        "id": "47d40116"
      },
      "source": [
        "Veamos el resultado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3bbf79e",
      "metadata": {
        "id": "a3bbf79e"
      },
      "outputs": [],
      "source": [
        "print(res.compute())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4a5d462",
      "metadata": {
        "id": "c4a5d462"
      },
      "source": [
        "* `merge`: al igual que en `pandas`, podemos unir dos o más `DataFrames` por medio de las operaciones `merge` y `join` (recuerde que `dask` lo hace de forma distribuida, lo cual es muy útil para cruzar tablas muy grandes), veamos un ejemplo donde definimos dos `DataFrames`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87645315",
      "metadata": {
        "id": "87645315"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame({\n",
        "        \"col1\": [1, 2, 3, 4, 5],\n",
        "        \"col2\": [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
        "        })\n",
        "df1 = dd.from_pandas(data, npartitions=1)\n",
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3873219f",
      "metadata": {
        "id": "3873219f"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame({\n",
        "        \"col1\": [1, 2, 3, 4],\n",
        "        \"col3\": [\"perro\", \"gato\", \"pajaro\", \"pez\"]\n",
        "        })\n",
        "df2 = dd.from_pandas(data, npartitions=1)\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9df894b0",
      "metadata": {
        "id": "9df894b0"
      },
      "source": [
        "Vamos a unir los dos `DataFrame` con la operación `merge`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72fd92de",
      "metadata": {
        "id": "72fd92de"
      },
      "outputs": [],
      "source": [
        "res = df1.merge(df2, on=\"col1\")\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c51a8855",
      "metadata": {
        "id": "c51a8855"
      },
      "source": [
        "Veamos el resultado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "901c982d",
      "metadata": {
        "id": "901c982d"
      },
      "outputs": [],
      "source": [
        "res.compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63834b4d",
      "metadata": {
        "id": "63834b4d"
      },
      "source": [
        "## **6. Filtrado**\n",
        "---\n",
        "\n",
        "La sintaxis para la selección de valores en `DataFrame` de `dask` es muy parecida a `pandas`, no obstante, hay algunas consideraciones en cuanto a que no se recomienda el indexado posicional, en especial por que tenemos datos distribuidos de los que no conocemos directamente su tamaño. Veamos algunos ejemplos:\n",
        "\n",
        "* Para seleccionar columnas, podemos indexar el `DataFrame` como si fuera un diccionario, por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3103a4ca",
      "metadata": {
        "id": "3103a4ca"
      },
      "outputs": [],
      "source": [
        "df2 = df[[\"type\", \"show_id\"]]\n",
        "print(df2.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb061235",
      "metadata": {
        "id": "cb061235"
      },
      "source": [
        "* Podemos usar el método `loc` para extraer datos con respecto a su índice:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b77e163",
      "metadata": {
        "id": "6b77e163"
      },
      "outputs": [],
      "source": [
        "df2 = df.loc[20:30]\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acf708ec",
      "metadata": {
        "id": "acf708ec"
      },
      "source": [
        "No obstante, el método `iloc` (indexado posicional) no funciona correctamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3900845d",
      "metadata": {
        "id": "3900845d"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    df2 = df.iloc[:10]\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a56e978",
      "metadata": {
        "id": "9a56e978"
      },
      "source": [
        "* Podemos hacer selecciones condicionales de la misma forma que en `pandas`, por ejemplo, seleccionamos todos los registros correspondientes al tipo `movie`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2eac24f",
      "metadata": {
        "id": "a2eac24f"
      },
      "outputs": [],
      "source": [
        "df2 = df[df.type == \"movie\"]\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00861f99",
      "metadata": {
        "id": "00861f99"
      },
      "source": [
        "Calculamos el resultado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26e69cfe",
      "metadata": {
        "id": "26e69cfe"
      },
      "outputs": [],
      "source": [
        "df2.compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03560f80",
      "metadata": {
        "id": "03560f80"
      },
      "source": [
        "* También podemos usar el método `query` para seleccionar valores de acuerdo a un criterio, tal y como funciona en `pandas`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "497330e9",
      "metadata": {
        "id": "497330e9"
      },
      "outputs": [],
      "source": [
        "df2 = df.query(\"type == 'movie'\")\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "540d6bcf",
      "metadata": {
        "id": "540d6bcf"
      },
      "source": [
        "Calculamos el resultado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8337e8d",
      "metadata": {
        "id": "f8337e8d"
      },
      "outputs": [],
      "source": [
        "df2.compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78a58e0d",
      "metadata": {
        "id": "78a58e0d"
      },
      "source": [
        "## **7. Comparativa con Pandas**\n",
        "---\n",
        "\n",
        "Veamos una comparativa en tiempo y memoria con respecto a los `DataFrame` de `pandas`, para ello, usaremos las librerías `psutil` y `time`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fbb2f95",
      "metadata": {
        "id": "3fbb2f95"
      },
      "outputs": [],
      "source": [
        "import psutil, time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cc61b4b",
      "metadata": {
        "id": "3cc61b4b"
      },
      "source": [
        "Veamos la diferencia en memoria entre la carga del `DataFrame` desde `pandas` y desde `dask`:\n",
        "\n",
        "* `pandas`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bdc8599",
      "metadata": {
        "id": "0bdc8599"
      },
      "outputs": [],
      "source": [
        "memory = psutil.virtual_memory()[2]\n",
        "print(f\"RAM inicial: {memory:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e18daaa5",
      "metadata": {
        "id": "e18daaa5"
      },
      "source": [
        "Cargamos el conjunto de datos con `pandas`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18655b20",
      "metadata": {
        "id": "18655b20"
      },
      "outputs": [],
      "source": [
        "df_pandas = pd.read_parquet(\"netflix2.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14a35d70",
      "metadata": {
        "id": "14a35d70"
      },
      "source": [
        "Veamos qué tanto subió la memoria RAM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0afc259",
      "metadata": {
        "id": "b0afc259"
      },
      "outputs": [],
      "source": [
        "memory = psutil.virtual_memory()[2]\n",
        "print(f\"RAM final: {memory:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5698508",
      "metadata": {
        "id": "b5698508"
      },
      "source": [
        "* `dask`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "395c781e",
      "metadata": {
        "id": "395c781e"
      },
      "outputs": [],
      "source": [
        "memory = psutil.virtual_memory()[2]\n",
        "print(f\"RAM inicial: {memory:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cb23c56",
      "metadata": {
        "id": "1cb23c56"
      },
      "source": [
        "Cargamos el conjunto de datos con `dask`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c97fe7b",
      "metadata": {
        "id": "7c97fe7b"
      },
      "outputs": [],
      "source": [
        "df_dask = dd.read_parquet(\"netflix2.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff343434",
      "metadata": {
        "id": "ff343434"
      },
      "source": [
        "Veamos qué tanto subió la memoria RAM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "168feb2c",
      "metadata": {
        "id": "168feb2c"
      },
      "outputs": [],
      "source": [
        "memory = psutil.virtual_memory()[2]\n",
        "print(f\"RAM final: {memory:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6b5584a",
      "metadata": {
        "id": "c6b5584a"
      },
      "source": [
        "Como puede ver `dask` no carga directamente el conjunto de datos en memoria. Ahora veamos una comparativa en tiempo en operaciones de agregación (se ven beneficiadas de paralelismo).\n",
        "\n",
        "* `pandas`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ac319e",
      "metadata": {
        "id": "d7ac319e"
      },
      "outputs": [],
      "source": [
        "t0 = time.time()\n",
        "res = df_pandas.groupby([\"type\", \"country\"]).agg({\"release_year\": \"mean\"})\n",
        "delta_t = time.time() - t0\n",
        "print(f\"Segundos: {delta_t:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cae31812",
      "metadata": {
        "id": "cae31812"
      },
      "source": [
        "* `dask`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50cfd3e3",
      "metadata": {
        "id": "50cfd3e3"
      },
      "outputs": [],
      "source": [
        "t0 = time.time()\n",
        "res = (\n",
        "        df_dask\n",
        "        .groupby([\"type\", \"country\"])\n",
        "        .agg({\"release_year\": \"mean\"})\n",
        "        .compute()\n",
        "        )\n",
        "delta_t = time.time() - t0\n",
        "print(f\"Segundos: {delta_t:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5cf57f7",
      "metadata": {
        "id": "b5cf57f7"
      },
      "source": [
        "Como podemos ver, el resultado demora más en `dask`. Recuerde que esta herramienta debe coordinar y gestionar multiples `DataFrame` que están contenidos en varias particiones, esto permite trabajar con grandes cantidades de datos. No obstante, si el conjunto de datos es pequeño `pandas` sigue siendo la mejor opción."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4e7bc49",
      "metadata": {
        "id": "b4e7bc49"
      },
      "source": [
        "## **8. Recursos Adicionales**\n",
        "---\n",
        "\n",
        "* [DataFrames de Dask](https://docs.dask.org/en/stable/dataframe.html).\n",
        "* [Dask - Talks & tutorials](https://docs.dask.org/en/stable/presentations.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "912960fb",
      "metadata": {
        "id": "912960fb"
      },
      "source": [
        "## **9. Créditos**\n",
        "---\n",
        "\n",
        "**Profesor**\n",
        "\n",
        "- [Jorge E. Camargo, PhD](https://dis.unal.edu.co/~jecamargom/)\n",
        "\n",
        "**Diseño, desarrollo del notebook y material audiovisual**\n",
        "\n",
        "- [Juan S. Lara MSc](https://www.linkedin.com/in/juan-sebastian-lara-ramirez-43570a214/)\n",
        "\n",
        "**Universidad Nacional de Colombia** - *Facultad de Ingeniería*"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}